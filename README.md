# Performance Prediction from DSL Models

This project predicts system performance metrics (avg/min/max response time) from software architecture DSL files.

---

## ğŸ”§ Features

- ğŸ§¾ Summary statistics prediction (avg, min, max response time)
- ğŸ” Embedding methods:
  - `TF-IDF`
  - `BERT (bert-base-uncased)`
- ğŸ§  Model types:
  - `Random Forest`
  - `Ridge` / `Lasso` Regression
  - `PyTorch Neural Network`
- ğŸ” Optional MLflow experiment tracking
- ğŸ“¦ Cleanly modular & easily extensible

---

## ğŸ“ Project Structure
```
palladio_approximator/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dsl_models/         # .tpcm files (DSL)
â”‚   â””â”€â”€ measurements/       # .csv files (Response Time [s])
â”œâ”€â”€ dataset.py              # Loads and preprocesses DSL + CSV
â”œâ”€â”€ feature_extraction.py   # TF-IDF + BERT embeddings
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rf_model.py         # Random forest trainer
â”‚   â”œâ”€â”€ linear_model.py     # Ridge / Lasso trainer
â”‚   â””â”€â”€ torch_model.py      # PyTorch neural network model
â”œâ”€â”€ evaluate.py             # Reusable model evaluation
â”œâ”€â”€ train.py                # Unified training script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How to Use

### 1. Prepare your data
- Place `.tpcm` files in `data/dsl_models/`
- Place matching `.csv` files in `data/measurements/`
- Files must have the same base name, e.g., `foo.tpcm` + `foo.csv`
- Alternatively, use `collect_files.py` to gather data from PCMs directory

### 2. Install dependencies

#### Using Nix (for development)
```bash
nix develop
```

#### Using Docker (for experiments)
```bash
./run.sh build   # Build the Docker image
./run.sh bash    # Start a bash shell in the container
```

#### Using pip
```bash
pip install -r requirements.txt
```

---

## ğŸ§ª Example Commands

### â¤ Train Random Forest with TF-IDF (baseline)
```bash
python train.py --model rf --embedding tfidf --prediction_mode summary
```

### â¤ Train Ridge Regression with TF-IDF
```bash
python train.py --model ridge --embedding tfidf --alpha 0.5
```

### â¤ Train with BERT embeddings on GPU
```bash
python train.py --model rf --embedding bert --use_cuda
```

### â¤ Enable MLflow tracking
```bash
python train.py --model rf --embedding bert --use_cuda --use_mlflow
```

### â¤ Using Docker
```bash
./run.sh train rf bert summary
```

---

## ğŸ“Š Output Files
- Trained models: `rf_model.pkl`, `ridge_model.pkl`, etc.
- Embedding models: `tfidf_embedding.pkl`, or BERT model/tokenizer objects
- `data/all_samples.csv`: Preprocessed dataset

---

## ğŸ”¬ Evaluation Script

You can import `evaluate.py` in any script:
```python
from evaluate import evaluate_model
results = evaluate_model(model, X_val, y_val, split_name="val")
```
This prints and returns MSE & MAE for each target (avg, min, max).

---

## ğŸ“Œ Notes on Reproducibility
- All model hyperparameters are logged.
- `--use_mlflow` stores experiments with:
  - Model type
  - Embedding method
  - Prediction mode
  - Key metrics
  - Model files
- This enables detailed experiment comparisons in the MLflow UI.

---

## â­ Coming Soon
- `--prediction_mode timeseries` for predicting values at individual timesteps
- Cross-validation scripts and more model types (e.g. MLPs)

---

## ğŸ“« Questions?
Open an issue or reach out!